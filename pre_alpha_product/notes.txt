Base logic
get data automate decisons
diversify accross exchanges, coins, capital (usd to btc btc to eth etc... )

computer a does coins 1 - 50
computer b does coins 51 - 100
computer c does coins 101 - 149
etc ( distri

get all coins avalible info: https://www.cryptocompare.com/api/data/coinlist/

features
(feature > x user approval) etc.


*determine frequency per api call
*determine buy sell logix

*****LOGICAL PLAN
start pulling storing data into envs
leverage metabase as ui for group to see determine trends
power users read access to data
    --> create py algo based on analysis
    --> create ML based on data --> algo
*****LOGICAL PLAN

PRICING information

process call api x,
    save json to directory on s3 --> hive data cluster (if not exists etc)  --> data mine --> create algo
        --> meta data profile into redshift / snapshot
    api results within python
        --> plug into algorhythm
            --> action (notify, buy/sell) (feature > x user approval) etc.
                --> log action/confirmation s3
                    --> meta data profile into redshift / snapshot


Metalogic/ information

general coin information
    process call api x,
        save json to directory on s3 --> hive --> analyze
            --> metadata profiles into redshift etc
    api results within python
        --> prompt when new crypto avalible



#### The big picture?
thousands of diffrent coins,

create "aggresive penny stock etfs kinda deal"
display correlation accross many cryptos
give access into mining/ buying said coins if avalible?
